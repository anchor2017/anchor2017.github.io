---
layout:     post
title:      使用python制作《围城》的人名词云
subtitle:   
date:       2019-07-16
author:     蔡银锚
header-img: img/bg-githubpages.jpg
catalog: true
tags:
    - python
    - 人名词云
    - 词频统计
---


###### [效果图](https://raw.githubusercontent.com/anchor2017/anchor2017.github.io/master/img/wcWordCloud.png)
![](https://raw.githubusercontent.com/anchor2017/anchor2017.github.io/master/img/wcWordCloud.jpg)
###### [地址：https://github.com/anchor2017/NameCloud.git](https://github.com/anchor2017/NameCloud.git)

#### 导包
```
import jieba        # 用于分词
from imageio import imread      # 用于处理背景图片
from wordcloud import WordCloud     # 用于图片显示
```

#### 导入背景图片
```
m1 = imread('bg2.jpg')
m2 = imread('china.jpg')
```

#### 准备高频无用词语库
```
excludes = {'&#', '8212', '自己', '没有', '什么', '知道', '他们', '一个', '可是',
            '先生', '太太', '我们', '你们', '不是', '可以', '现在', '东西', '不会', '唐小姐',
            '所以', '觉得', '咱们', '因为', '大家', '不要', '不过', '结婚', '中国', '出来',
            '的话', '起来', '也许', '明天', '就是', '仿佛', '人家', '为什么', '忽然', '以后',
            '女人', '今天', '学生', '这样', '时候', '鸿渐', '辛楣', '小姐', '孙小姐', '柔嘉',
            '家里', '学校', '不能', '只有', '心里', '告诉', '这种', '这个', '怎么', '李先生',
            '回来', '还是', '校长', '当然', '看见', '上海', '大学', '这时候', '是不是', '父亲',}
``` 
 

#### 分词
```
with open('weicheng.txt', 'r', encoding='utf8') as f:       # 使用文件上下文管理器来打开文件
    text = f.read()
wordList = jieba.lcut(text)     # 使用精确切割
```

#### 统计词语出现的次数
```
d = {}  # {}表示声明一个字典
for i in wordList:
    if len(i) == 1:     # 清除一个字的词语
        continue
    else:
        d[i] = d.get(i, 0) + 1      # get()方法可以用于第一次的初始化，此后对于每一个词语计数加一
```

#### 词语合计
```
# 词频整合
d['方鸿渐'] = d['鸿渐'] + d['方鸿渐']
d['赵辛楣'] = d['辛楣'] + d['赵辛楣']
d['孙柔嘉'] = d['柔嘉'] + d['孙小姐'] + d['孙柔嘉']
d['唐晓芙'] = d['晓芙'] + d['唐小姐']
d['李梅亭'] = d['梅亭'] + d['李梅亭'] + d['李先生']
d['鲍小姐'] = d['小姐'] - d['孙小姐'] - d['唐小姐']
```

#### 去除无用词语
```
# 手动去除高频非人名的词语，这里可以考虑用包含《围城》本书的所有人名来实现
for i in excludes:
    del d[i]
```

#### 将字典转化为列表
```
# 排序    lambda(if) 参数: 返回值  元组里面的第二个元素
l = list(d.items())
l.sort(key=lambda x: x[1], reverse=True)    # 对词语列表的所有词语的词频进行排序
```

#### 拼接成字符串
```
nameList = []
for i in range(8):      # 取前八个单词
    name, counts = l[i]
    for i in range(counts):
        nameList.append(name)
```

#### 手动添加词频过低的名字
```
# 这里可以直接考虑用包含《围城》本书的所有人名来简化这部分的代码
for i in range(44):
    nameList.append('韩学愈')
for i in range(53):
    nameList.append('汪处厚')
for i in range(38):
    nameList.append('刘东方')
for i in range(30+29):
    nameList.append('顾尔谦')
for i in range(24):
    nameList.append('苏文纨')
for i in range(20):
    nameList.append('褚慎明')
for i in range(20+7):
    nameList.append('董斜川')
for i in range(35):
    nameList.append('曹元朗')
for i in range(22):
    nameList.append('陆子潇')
for i in range(3):
    nameList.append('范懿')
```

#### 空格连接
```
str = ' '.join(nameList)        # 字符串用空格拼接 使用字符串的.join()方法
```

#### 图片显示
```
# 字体黑体，背景白色
wc = WordCloud(mask=m1, collocations=False, font_path='simhei.ttf',
                background_color='white').generate(str)
wc.to_file('pic1.png')      # 写入文件
wc = WordCloud(mask=m2, collocations=False, font_path='simhei.ttf',
                background_color='white').generate(str)
wc.to_file('pic2.png')
```


